# DPDK TX Path: Multi-Layer Architecture Overview

> **Document Purpose**: Understanding DPDK's layered architecture, data structures, and packet I/O flow
> **Created**: 2025-01-05
> **Project**: DPDK Performance Benchmarking & Optimization

---

## Table of Contents

1. [High-Level Architecture Overview](#1-high-level-architecture-overview)
2. [Complete Layer Stack Diagram (Detailed)](#2-complete-layer-stack-diagram-detailed)
3. [Data Structure Ownership & Lifecycle](#3-data-structure-ownership--lifecycle)
4. [TX Path Flow with Data Structures](#4-tx-path-flow-with-data-structures)
5. [Key Indices & Queue Depth Calculation](#5-key-indices--queue-depth-calculation)
6. [Our Tracking Points](#6-our-tracking-points)
7. [Configuration Bug Fixed](#7-configuration-bug-fixed)
8. [Summary Table](#8-summary-table)

---

## 1. High-Level Architecture Overview

### DPDK 4-Layer Architecture

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ  APPLICATION LAYER                                                  â”ƒ
â”ƒ  â€¢ Packet generation logic (Pktgen)                                 â”ƒ
â”ƒ  â€¢ Business logic, TX/RX orchestration                              â”ƒ
â”ƒ  â€¢ Temporary working buffers (pointer arrays)                       â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â†“ Uses APIs
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ  DPDK CORE LIBRARIES LAYER (librte_* - Run-Time Environment)        â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”ƒ
â”ƒ  â”‚  MEMPOOL     â”‚  MBUF        â”‚  ETHDEV                      â”‚    â”ƒ
â”ƒ  â”‚  (Container) â”‚  (Object)    â”‚  (API Abstraction)           â”‚    â”ƒ
â”ƒ  â”‚              â”‚              â”‚                              â”‚    â”ƒ
â”ƒ  â”‚  Memory pool â”‚  Packet      â”‚  Unified API for all NICs   â”‚    â”ƒ
â”ƒ  â”‚  management  â”‚  buffer:     â”‚  â€¢ rte_eth_tx_burst()        â”‚    â”ƒ
â”ƒ  â”‚              â”‚  metadata +  â”‚  â€¢ rte_eth_rx_burst()        â”‚    â”ƒ
â”ƒ  â”‚              â”‚  data        â”‚                              â”‚    â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â†“ Dispatches to PMD
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ  PMD LAYER (Poll Mode Driver)                                       â”ƒ
â”ƒ  â€¢ Hardware-specific driver (MLX5, i40e, etc.)                      â”ƒ
â”ƒ  â€¢ WQE ring management (hardware descriptors)                       â”ƒ
â”ƒ  â€¢ Completion queue polling                                         â”ƒ
â”ƒ  â€¢ DMA setup and doorbell operations                                â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â†“ DMA operations
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ  HARDWARE LAYER (NIC)                                               â”ƒ
â”ƒ  â€¢ Physical network interface card                                  â”ƒ
â”ƒ  â€¢ DMA engine, on-chip queues                                       â”ƒ
â”ƒ  â€¢ Wire transmission/reception                                      â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â†“
                      [ Network Wire ]
```

### Key Concepts

**Layer Separation**:
- **Application**: Business logic, uses DPDK APIs
- **DPDK Core Libraries**: Reusable infrastructure (mempool, mbuf, ethdev)
- **PMD**: Hardware-specific drivers (Intel, Mellanox, etc.)
- **Hardware**: Physical NIC

**Data Ownership**:
- **Application**: Holds pointers only (temporary arrays)
- **DPDK Core**: Owns actual memory (mbufs, rings)
- **PMD**: Manages hardware descriptors (WQEs)
- **Hardware**: Physical transmission

**API Flow** (TX path):
```
Application:  rte_mempool_get_bulk()  â†’  get mbufs
              rte_eth_tx_burst()       â†’  submit packets

DPDK Core:    ethdev dispatch         â†’  calls PMD function pointer

PMD:          mlx5_tx_burst()          â†’  write WQEs, ring doorbell
              mlx5_tx_completion()     â†’  poll CQ, return mbufs

              rte_mempool_put_bulk()   â†’  return to pool
```

---

## 2. Complete Layer Stack Diagram (Detailed)

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                                      APPLICATION LAYER (Pktgen)                                                â”ƒ
â”ƒ                                                                                                                â”ƒ
â”ƒ  ğŸ“ Code Location: Pktgen-DPDK/app/pktgen.c                                                                   â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”ƒ
â”ƒ  â”‚  ğŸ”§ TX Logic Functions & API Calls:                                                                    â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  [INITIALIZATION - Once at startup]                                                                    â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen_packet_ctor() (pktgen.c:750) - Construct packet templates                                   â”‚   â”ƒ
â”ƒ  â”‚    Creates pre-filled packets with headers (Ethernet, IP, TCP) and payload                            â”‚   â”ƒ
â”ƒ  â”‚    âš ï¸  Packet template reuse: pre-filled packets reused every burst                                   â”‚   â”ƒ
â”ƒ  â”‚    âš ï¸  NOT real TCP, just benchmark tool (e.g., sequence numbers are not correct)                     â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen_tx_workq_setup() (pktgen.c:1475) - Register TX functions to work queue                      â”‚   â”ƒ
â”ƒ  â”‚    API: workq_add(WORKQ_TX, pid, pktgen_main_transmit) (pktgen.c:1488)                               â”‚   â”ƒ
â”ƒ  â”‚    Registers pktgen_main_transmit() for repeated execution in main loop                                 â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  [FAST PATH TX - Main transmit loop]                                                                   â”‚   â”ƒ
â”ƒ  â”‚  Per-core main loop (pktgen_main_rxtx_loop at pktgen.c:1556):                                        â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Each lcore runs independent loop: lid = rte_lcore_id() (pktgen.c:1560)                            â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Each lcore handles its own qid: rx_qid = l2p_get_rxqid(lid) (pktgen.c:1574)                       â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  Main loop (pktgen.c:1585) repeatedly calls:                                                          â”‚   â”ƒ
â”ƒ  â”‚  â€¢ workq_run(WORKQ_TX, pid, qid) - Execute all registered TX functions                               â”‚   â”ƒ
â”ƒ  â”‚    Work queue mechanism: functions registered once, executed every iteration                          â”‚   â”ƒ
â”ƒ  â”‚    â†’ Calls pktgen_main_transmit() (registered via workq_add at startup)                              â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen_main_transmit() (pktgen.c:1339) - Determine next packet format                              â”‚   â”ƒ
â”ƒ  â”‚    Gets port-specific TX mempool: mp = l2p_get_tx_mp(pid) (pktgen.c:1348)                            â”‚   â”ƒ
â”ƒ  â”‚    â†’ Calls pktgen_send_pkts(pinfo, qid, mp)                                                           â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen_send_pkts() (pktgen.c:1307) - Get mbufs from mempool                                        â”‚   â”ƒ
â”ƒ  â”‚    API: rte_mempool_get_bulk(mp, (void **)pkts, txCnt) (pktgen.c:1323)                                â”‚   â”ƒ
â”ƒ  â”‚    â†’ Calls tx_send_packets()                                                                           â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  â€¢ tx_send_packets() (pktgen.c:463) - Core TX with retry logic                                        â”‚   â”ƒ
â”ƒ  â”‚    API: rte_eth_tx_burst(pid, qid, pkts, to_send) (pktgen.c:569)                                      â”‚   â”ƒ
â”ƒ  â”‚    - Retry loop handles partial sends                                                                 â”‚   â”ƒ
â”ƒ  â”‚    - Tracks TX producer count & burst timing (AK)                                                      â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  [ALTERNATIVE FAST PATH - Zero-overhead mode]                                                          â”‚   â”ƒ
â”ƒ  â”‚  â€¢ fast_main_transmit() (pktgen.c:1360) - Optimized TX without special packets                        â”‚   â”ƒ
â”ƒ  â”‚    API: rte_mempool_get_bulk(mp, (void **)pkts, tx_burst) (pktgen.c:1367)                             â”‚   â”ƒ
â”ƒ  â”‚    API: rte_eth_tx_burst(pid, qid, pkts, send) (pktgen.c:1370)                                        â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  [RX PATH]                                                                                             â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen_main_receive() (pktgen.c:1391) - Main receive routine                                       â”‚   â”ƒ
â”ƒ  â”‚    Handles received packets and input processing                                                      â”‚   â”ƒ
â”ƒ  â”‚                                                                                                         â”‚   â”ƒ
â”ƒ  â”‚  [RATE LIMITING]                                                                                       â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Rate control logic - Control TX speed via TSC-based burst intervals                                â”‚   â”ƒ
â”ƒ  â”‚    Implemented in tx_send_packets()                                                                    â”‚   â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”ƒ
â”ƒ                                                                                                           â”ƒ
â”ƒ  ğŸ’¾ Data Structures:                                                                                      â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”ƒ
â”ƒ  â”‚  ğŸ“Š Temporary Working Buffers (NOT actual rings!)                                                 â”‚   â”ƒ
â”ƒ  â”‚                                                                                                    â”‚   â”ƒ
â”ƒ  â”‚  RX Working Buffer:                                                                               â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pinfo->rx_pkts[qid]  - Temporary array of mbuf pointers (pktgen-port-cfg.c:195)               â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Size: MAX_PKT_RX_BURST (typically 32)                                                          â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Purpose: Working space for rte_eth_rx_burst() to fill received packet pointers                â”‚   â”ƒ
â”ƒ  â”‚  â€¢ âš ï¸  NOT the actual RX ring! (actual ring created by rte_eth_rx_queue_setup in DPDK Core)      â”‚   â”ƒ
â”ƒ  â”‚                                                                                                    â”‚   â”ƒ
â”ƒ  â”‚  TX Working Buffer:                                                                               â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pinfo->tx_pkts[qid]  - Temporary array of mbuf pointers (pktgen-port-cfg.c:198)               â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Size: MAX_PKT_TX_BURST (typically 32)                                                          â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Populated by: rte_mempool_get_bulk() - gets mbuf pointers from DPDK Core mempool              â”‚   â”ƒ
â”ƒ  â”‚  â€¢ Consumed by: rte_eth_tx_burst() - passes pointers to DPDK Core for transmission               â”‚   â”ƒ
â”ƒ  â”‚  â€¢ âš ï¸  NOT the actual TX ring! (actual ring created by rte_eth_tx_queue_setup in DPDK Core)      â”‚   â”ƒ
â”ƒ  â”‚                                                                                                    â”‚   â”ƒ
â”ƒ  â”‚  âš™ï¸  Configuration (for DPDK Core layer rings, not application buffers):                          â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen.nb_rxd = DEFAULT_RX_DESC  (default 1024) - RX ring size in DPDK Core                   â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pktgen.nb_txd = DEFAULT_TX_DESC  (default 1024) - TX ring size in DPDK Core                   â”‚   â”ƒ
â”ƒ  â”‚    API: rte_eth_tx_queue_setup(pid, q, pktgen.nb_txd, ...) (pktgen-port-cfg.c:493)               â”‚   â”ƒ
â”ƒ  â”‚    API: rte_eth_rx_queue_setup(pid, q, pktgen.nb_rxd, ...) (pktgen-port-cfg.c:477)               â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pinfo->tx_burst - Number of packets per burst (typically 32) - working buffer size            â”‚   â”ƒ
â”ƒ  â”‚  â€¢ pinfo->rx_burst - Number of packets per RX burst (typically 32) - working buffer size         â”‚   â”ƒ
â”ƒ  â”‚                                                                                                    â”‚   â”ƒ
â”ƒ  â”‚  âœ… Key Insight: Application only holds pointers; actual memory allocated in DPDK Core            â”‚   â”ƒ
â”ƒ  â”‚     - Actual mbuf memory: allocated in DPDK Core Mempool                                          â”‚   â”ƒ
â”ƒ  â”‚     - Actual TX/RX rings: created in DPDK Core Ethdev/PMD layer                                   â”‚   â”ƒ
â”ƒ  â”‚     - Application: writes packet data via pointers; only holds temporary pointer arrays           â”‚   â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â”‚
                            â”‚ Application â†’ DPDK Core APIs:
                            â”‚ â€¢ rte_mempool_get_bulk() - Get mbuf pointers
                            â”‚ â€¢ rte_eth_tx_burst() / rx_burst() - Submit/receive packets
                            â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                                          DPDK CORE LIBRARIES LAYER (librte_* - Run-Time Environment)                                 â”ƒ
â”ƒ                                                                                                                                      â”ƒ
â”ƒ  ğŸ“ Code Location: dpdk/lib/                                                                                                        â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  ğŸ“¦ MEMPOOL LIBRARY                  â”‚  ğŸ“‹ MBUF LIBRARY                         â”‚  ğŸ”Œ ETHDEV LIBRARY                          â”‚ â”ƒ
â”ƒ  â”‚  (Memory Pool Management)            â”‚  (Packet Buffer: Metadata + Data)        â”‚  (Ethernet Device Abstraction)              â”‚ â”ƒ
â”ƒ  â”‚  dpdk/lib/mempool/rte_mempool.h      â”‚  dpdk/lib/mbuf/rte_mbuf.h                â”‚  dpdk/lib/ethdev/rte_ethdev.h               â”‚ â”ƒ
â”ƒ  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”ƒ
â”ƒ  â”‚  Concept:                            â”‚  Concept:                                â”‚  Concept:                                   â”‚ â”ƒ
â”ƒ  â”‚  Container                           â”‚  Object                                  â”‚  API Abstraction                            â”‚ â”ƒ
â”ƒ  â”‚  Stores objects efficiently          â”‚  Stored in mempool                       â”‚  Dispatches to PMD via function pointers    â”‚ â”ƒ
â”ƒ  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”ƒ
â”ƒ  â”‚  Data Structure:                     â”‚  Data Structure:                         â”‚  Data Structure:                            â”‚ â”ƒ
â”ƒ  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ struct rte_mempool             â”‚  â”‚  â”‚ struct rte_mbuf                    â”‚  â”‚  â”‚ struct rte_eth_dev                    â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ (Name: TX-L1/P0/S0)            â”‚  â”‚  â”‚ (Size: 2,176 bytes each)           â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ created by lcore1, but shared  â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚ Metadata Only (No packet storage!):   â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”“  â”‚  â”‚  â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“   â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”ƒ mbuf â”ƒ mbuf â”ƒ mbuf â”ƒ mbuf â”ƒ  â”‚  â”‚  â”‚ â”ƒ Metadata Section:            â”ƒ   â”‚  â”‚  â”‚ â€¢ tx_pkt_burst  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’    â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”ƒ  0   â”ƒ  1   â”ƒ  2   â”ƒ  3   â”ƒ  â”‚  â”‚  â”‚ â”ƒ â€¢ packet_length              â”ƒ   â”‚  â”‚  â”‚   mlx5_tx_burst()                     â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”—â”â”â”â”â”â”â”»â”â”â”â”â”â”â”»â”â”â”â”â”â”â”»â”â”â”â”â”â”â”›  â”‚  â”‚  â”‚ â”ƒ â€¢ data_offset                â”ƒ   â”‚  â”‚  â”‚   (function pointer)                  â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”“  â”‚  â”‚  â”‚ â”ƒ â€¢ reference_count (refcnt)   â”ƒ   â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”ƒ mbuf â”ƒ mbuf â”ƒ  ...  â”ƒ mbufâ”ƒ  â”‚  â”‚  â”‚ â”ƒ â€¢ offload_flags              â”ƒ   â”‚  â”‚  â”‚ â€¢ rx_pkt_burst  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’    â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”ƒ  4   â”ƒ  5   â”ƒ       â”ƒ  N  â”ƒ  â”‚  â”‚  â”‚ â”ƒ â€¢ mbuf_mempool pointer       â”ƒ   â”‚  â”‚  â”‚   mlx5_rx_burst()                     â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â”—â”â”â”â”â”â”â”»â”â”â”â”â”â”â”»â”â”â”â”â”â”â”»â”â”â”â”â”â”â”›  â”‚  â”‚  â”‚ â”ƒ                              â”ƒ   â”‚  â”‚  â”‚   (function pointer)                  â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚                                â”‚  â”‚  â”‚ â”ƒ Packet Data Section:         â”ƒ   â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ Total: 32,768 mbufs            â”‚  â”‚  â”‚ â”ƒ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ   â”‚  â”‚  â”‚ â€¢ Port configuration:                 â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚                                â”‚  â”‚  â”‚ â”ƒ â”‚ Ethernet | IP | TCP | ...â”‚ â”ƒ   â”‚  â”‚  â”‚   - Link speed, duplex                â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   get_bulk()                   â”‚  â”‚  â”‚ â”ƒ â”‚ (Actual network packet)  â”‚ â”ƒ   â”‚  â”‚  â”‚   - MTU size                          â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   Called by Application        â”‚  â”‚  â”‚ â”ƒ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ   â”‚  â”‚  â”‚   - Offload capabilities              â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚                                â”‚  â”‚  â”‚ â”ƒ (up to 2,048 bytes)          â”ƒ   â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   put_bulk()                   â”‚  â”‚  â”‚ â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›   â”‚  â”‚  â”‚ â€¢ Queue metadata:                     â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   Called by PMD (on completion)â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚   - Number of RX queues               â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚                                â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚   - Number of TX queues               â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ Features:                      â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚   - Queue descriptors                 â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â€¢ Per-port shared mempool      â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   (all lcores using that port) â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ â€¢ Per-core cache for           â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚ â„¹ï¸  Pure metadata - no actual         â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   performance optimization     â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚    packet data stored here!           â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚   (MEMPOOL_CACHE_SIZE)         â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚                                â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â”‚ âš ï¸ Potential contention point! â”‚  â”‚  â”‚                                    â”‚  â”‚  â”‚                                       â”‚  â”‚ â”ƒ
â”ƒ  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”ƒ
â”ƒ  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”ƒ
â”ƒ  â”‚  ğŸ”§ API Usage Flow:                  â”‚  ğŸ”§ API Usage:                           â”‚  ğŸ”§ API Usage Flow:                         â”‚ â”ƒ
â”ƒ  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”ƒ
â”ƒ  â”‚  [INITIALIZATION - Once at startup]  â”‚  [SLOW PATH - NOT Pktgen fast path!]     â”‚  [FAST PATH TX - Every burst]               â”‚ â”ƒ
â”ƒ  â”‚  Application calls:                  â”‚                                          â”‚  Application calls:                         â”‚ â”ƒ
â”ƒ  â”‚  rte_mempool_create(                 â”‚  rte_pktmbuf_alloc(mempool)              â”‚  rte_eth_tx_burst(                          â”‚ â”ƒ
â”ƒ  â”‚    "TX-L1/P0/S0",                    â”‚  â€¢ Allocate single mbuf                  â”‚    port_id, queue_id,                       â”‚ â”ƒ
â”ƒ  â”‚    32768,                            â”‚  â€¢ Slower than bulk operations           â”‚    mbufs[], 32)                             â”‚ â”ƒ
â”ƒ  â”‚    sizeof(struct rte_mbuf),          â”‚                                          â”‚  (pktgen.c:569)                             â”‚ â”ƒ
â”ƒ  â”‚    ...)                              â”‚  rte_pktmbuf_free(mbuf)                  â”‚  â†’ Generic API (works for any NIC driver)   â”‚ â”ƒ
â”ƒ  â”‚  â†’ Creates pool with 32,768 mbufs    â”‚  â€¢ Free single mbuf                      â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚                                      â”‚  â€¢ Slower than bulk operations           â”‚  â†’ Internally dispatches to:                â”‚ â”ƒ
â”ƒ  â”‚  [FAST PATH TX - Every burst]        â”‚                                          â”‚    dev->tx_pkt_burst(...)                   â”‚ â”ƒ
â”ƒ  â”‚  Application (Pktgen) calls:         â”‚  âš ï¸  Pktgen does NOT use these APIs!     â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  rte_mempool_get_bulk(               â”‚     Uses mempool bulk APIs instead       â”‚  â†’ Calls PMD-specific implementation:       â”‚ â”ƒ
â”ƒ  â”‚    mempool, mbufs[], 32)             â”‚     for better performance!              â”‚    mlx5_tx_burst()                          â”‚ â”ƒ
â”ƒ  â”‚  (pktgen.c:1323)                     â”‚                                          â”‚    via function pointer                     â”‚ â”ƒ
â”ƒ  â”‚  â†’ Gets 32 pre-filled mbufs          â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  â†’ Zero-copy reuse pattern!          â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚                                      â”‚                                          â”‚  â†’ PMD writes to hardware TX queue          â”‚ â”ƒ
â”ƒ  â”‚  [COMPLETION PATH - After TX]        â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  PMD (MLX5 driver) calls:            â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  rte_mempool_put_bulk(               â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚    mempool, mbufs[], 32)             â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  (mlx5_tx.h:566 or :621)             â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  â†’ Returns 32 completed mbufs        â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â”‚  â†’ Back to pool for reuse            â”‚                                          â”‚                                             â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                                        â”ƒ
â”ƒ  âœ¨ Key Insight: Relationship between Mempool and mbuf                                 â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”ƒ
â”ƒ  â”‚  Mempool = Parking Lot (Container)     |  mbuf = Car (Object)                   â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Stores objects efficiently          |  â€¢ Packet data + metadata              â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Allocation/deallocation management  |  â€¢ Stored in Mempool                   â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Performance optimization via        |  â€¢ 2,176 bytes per mbuf                â”‚  â”ƒ
â”ƒ  â”‚    per-core cache                      |                                        â”‚  â”ƒ
â”ƒ  â”‚                                                                                  â”‚  â”ƒ
â”ƒ  â”‚  "mbuf Mempool" = Mempool that stores mbuf-type objects                         â”‚  â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â”‚
                            â”‚ DPDK Core â‡„ PMD APIs:
                            â”‚ â€¢ DPDK Core â†’ PMD: rte_eth_tx_burst() dispatches to mlx5_tx_burst()
                            â”‚ â€¢ PMD â†’ DPDK Core: rte_mempool_put_bulk() returns completed mbufs
                            â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                    PMD LAYER (MLX5 Driver)                          â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  ğŸ“ Code Location: dpdk/drivers/net/mlx5/mlx5_tx.h                 â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  ğŸ”§ TX Functions:                                            â”‚ â”ƒ
â”ƒ  â”‚  â€¢ mlx5_tx_burst()          - Main TX entry point           â”‚ â”ƒ
â”ƒ  â”‚  â€¢ mlx5_tx_handle_          - Process completions           â”‚ â”ƒ
â”ƒ  â”‚    completion()                                              â”‚ â”ƒ
â”ƒ  â”‚  â€¢ mlx5_tx_free_elts()      - Free completed mbufs          â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  ğŸ’¾ Data Structures:                                               â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  âš ï¸  IMPORTANT: Both structures below are in host memory!          â”ƒ
â”ƒ  â€¢ Left:  WQE Ring (SQ) - descriptor ring (NIC reads via DMA)      â”ƒ
â”ƒ  â€¢ Right: TX Control Structure - manages WQE Ring (driver uses)    â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  ğŸ“ Size Determination (mlx5_txq.c:1135, 1168, 708):               â”ƒ
â”ƒ  â€¢ By DEFAULT_TX_DESC (Default: 1024)                  â”ƒ
â”ƒ  â€¢ Both sizes determined from same desc parameter:                 â”ƒ
â”ƒ    - elts[] size = desc (mlx5_txq.c:1168)                          â”ƒ
â”ƒ    - WQE Ring size = 1 << log2above(desc) (mlx5_txq.c:708)         â”ƒ
â”ƒ  â€¢ âš ï¸  desc is rounded up to nearest power of 2!                   â”ƒ
â”ƒ    (e.g., desc=1000 â†’ WQE Ring=1024, elts[]=1024)                  â”ƒ
â”ƒ  â€¢ Both arrays guaranteed same size (1:1 parallel mapping)         â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”ƒ
â”ƒ  â”‚  âš™ï¸  WQE Ring (SQ)        â”‚  ğŸ›ï¸  TX Control Structure        â”‚â”ƒ
â”ƒ  â”‚     (Send Queue)          â”‚     (struct mlx5_txq_data)       â”‚â”ƒ
â”ƒ  â”‚                           â”‚                                  â”‚â”ƒ
â”ƒ  â”‚  Work Instructions for NIC:â”‚  Management Fields:              â”‚â”ƒ
â”ƒ  â”‚  â”â”â”â”â”â”â”³â”â”â”â”â”â”³â”â”â”â”â”â”“     â”‚  â€¢ wqe_ci - WQE Ring consumer idxâ”‚â”ƒ
â”ƒ  â”‚  â”ƒWQE0 â”ƒWQE1 â”ƒWQE2 â”ƒ...  â”‚  â€¢ wqe_pi - WQE Ring producer idxâ”‚â”ƒ
â”ƒ  â”‚  â”—â”â”â”â”â”â”»â”â”â”â”â”â”»â”â”â”â”â”â”›     â”‚  â€¢ wqe_s  - WQE Ring size (1024) â”‚â”ƒ
â”ƒ  â”‚       â†• parallel â†•        â”‚  â€¢ wqes   - pointer â†’ WQE Ring   â”‚â”ƒ
â”ƒ  â”‚  â”â”â”â”â”â”â”³â”â”â”â”â”â”³â”â”â”â”â”â”“     â”‚                                  â”‚â”ƒ
â”ƒ  â”‚  â”ƒelts0â”ƒelts1â”ƒelts2â”ƒ...  â”‚  Parallel mbuf tracking:         â”‚â”ƒ
â”ƒ  â”‚  â”—â”â”â”â”â”â”»â”â”â”â”â”â”»â”â”â”â”â”â”›     â”‚  â€¢ elts[] - mbuf pointer array   â”‚â”ƒ
â”ƒ  â”‚                           â”‚    (parallel to WQE Ring)        â”‚â”ƒ
â”ƒ  â”‚  Each WQE (descriptor):   â”‚  â€¢ elts[i] â†” WQE[i]              â”‚â”ƒ
â”ƒ  â”‚  Tells NIC how to process:â”‚  â€¢ Stores mbuf ptr while WQE[i]  â”‚â”ƒ
â”ƒ  â”‚  â€¢ pbuf   - where to read â”‚    is in-flight                  â”‚â”ƒ
â”ƒ  â”‚    (DMA addr, NOT mbuf*)  â”‚  â€¢ Retrieved on completion for   â”‚â”ƒ
â”ƒ  â”‚  â€¢ bcount - how many bytesâ”‚    mempool return                â”‚â”ƒ
â”ƒ  â”‚  â€¢ lkey   - memory key    â”‚                                  â”‚â”ƒ
â”ƒ  â”‚                           â”‚                                  â”‚â”ƒ
â”ƒ  â”‚  âš ï¸  Descriptor = work     â”‚  Why elts[] needed:              â”‚â”ƒ
â”ƒ  â”‚  instruction for NIC,     â”‚  â€¢ NIC only understands DMA      â”‚â”ƒ
â”ƒ  â”‚  NOT data itself!         â”‚    addresses, not virtual        â”‚â”ƒ
â”ƒ  â”‚  â€¢ NIC reads WQE via DMA  â”‚    pointers (mbuf*)              â”‚â”ƒ
â”ƒ  â”‚  â€¢ Executes: "read pbuf,  â”‚  â€¢ WQE[i] has DMA addr (for NIC) â”‚â”ƒ
â”ƒ  â”‚    send bcount bytes"     â”‚  â€¢ elts[i] has mbuf* (for driver)â”‚â”ƒ
â”ƒ  â”‚                           â”‚  â€¢ On completion: driver uses    â”‚â”ƒ
â”ƒ  â”‚                           â”‚    elts[i] to return mbuf        â”‚â”ƒ
â”ƒ  â”‚  â€¢ DMA-mapped memory      â”‚                                  â”‚â”ƒ
â”ƒ  â”‚  â€¢ Size: 1024 (default)   â”‚                                  â”‚â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”ƒ
â”ƒ  â”‚  âœ… Completion Queue (CQ)                                      â”‚â”ƒ
â”ƒ  â”‚  â€¢ Hardware writes completion status here                     â”‚â”ƒ
â”ƒ  â”‚  â€¢ Driver polls CQ to free mbufs (no interrupts)              â”‚â”ƒ
â”ƒ  â”‚  â€¢ Updates wqe_ci when packets complete                       â”‚â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  âš ï¸  IMPORTANT: Physical Memory Location                           â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”ƒ
â”ƒ  â”‚  WQE Ring & CQ Location: HOST MEMORY (NOT on NIC chip!)       â”‚â”ƒ
â”ƒ  â”‚                                                                 â”‚â”ƒ
â”ƒ  â”‚  Evidence: drivers/common/mlx5/mlx5_common_devx.c:118-127      â”‚â”ƒ
â”ƒ  â”‚  ```                                                            â”‚â”ƒ
â”ƒ  â”‚  /* Allocate memory buffer for CQEs and doorbell record. */    â”‚â”ƒ
â”ƒ  â”‚  umem_size = sizeof(struct mlx5_cqe) * num_of_cqes;            â”‚â”ƒ
â”ƒ  â”‚  umem_buf = mlx5_malloc_numa_tolerant(..., socket);            â”‚â”ƒ
â”ƒ  â”‚                    â†‘                                            â”‚â”ƒ
â”ƒ  â”‚            Host memory allocation!                              â”‚â”ƒ
â”ƒ  â”‚                                                                 â”‚â”ƒ
â”ƒ  â”‚  /* Register allocated buffer with DevX for DMA access */      â”‚â”ƒ
â”ƒ  â”‚  umem_obj = mlx5_os_umem_reg(ctx, umem_buf, umem_size,         â”‚â”ƒ
â”ƒ  â”‚                               IBV_ACCESS_LOCAL_WRITE);          â”‚â”ƒ
â”ƒ  â”‚                    â†‘                                            â”‚â”ƒ
â”ƒ  â”‚            DMA-capable memory registration                      â”‚â”ƒ
â”ƒ  â”‚  ```                                                            â”‚â”ƒ
â”ƒ  â”‚                                                                 â”‚â”ƒ
â”ƒ  â”‚  Memory Architecture:                                           â”‚â”ƒ
â”ƒ  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚â”ƒ
â”ƒ  â”‚  â”‚ HOST MEMORY (RAM)                                    â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ WQE Ring (SQ)      â”‚ â† PMD allocates              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ - DMA-mapped       â”‚   (Host RAM)                 â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ - NIC reads (DMA)  â”‚                              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚          â†‘ DMA Read                                  â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ Completion Queue   â”‚ â† PMD allocates              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ - DMA-mapped       â”‚   (Host RAM)                 â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ - NIC writes (DMA) â”‚                              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚      â”‚â”ƒ
â”ƒ  â”‚  â”‚          â†‘ DMA Write                                 â”‚      â”‚â”ƒ
â”ƒ  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚â”ƒ
â”ƒ  â”‚             â”‚                                                   â”‚â”ƒ
â”ƒ  â”‚             â”‚ PCIe Bus (DMA transfers)                          â”‚â”ƒ
â”ƒ  â”‚             â†“                                                   â”‚â”ƒ
â”ƒ  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚â”ƒ
â”ƒ  â”‚  â”‚ NIC HARDWARE (On-chip)                              â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ Internal FIFO    â”‚ â† Software cannot access      â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  â”‚ (HW-only buffer) â”‚   (NIC internal only)         â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  TX Engine (DMA controller)                         â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  - Reads WQEs from host memory via DMA              â”‚       â”‚â”ƒ
â”ƒ  â”‚  â”‚  - Writes CQEs to host memory via DMA               â”‚       â”‚â”ƒ
â”ƒ  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚â”ƒ
â”ƒ  â”‚                                                                 â”‚â”ƒ
â”ƒ  â”‚  Key Distinction:                                               â”‚â”ƒ
â”ƒ  â”‚  â€¢ WQE Ring/CQ: Host memory (DMA-mapped, PMD manages)          â”‚â”ƒ
â”ƒ  â”‚  â€¢ On-chip FIFO: NIC chip (HW-only, not accessible by SW)      â”‚â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                            â”‚
                            â”‚ ğŸš€ DMA Transfer & Doorbell Ring
                            â†“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                     HARDWARE LAYER (NIC)                            â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  ğŸ”Œ Device: Mellanox ConnectX-5 (MLX5)                            â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  ğŸš€ TX Engine:                                               â”‚ â”ƒ
â”ƒ  â”‚  â€¢ Reads WQEs via DMA      - Fetch descriptors               â”‚ â”ƒ
â”ƒ  â”‚  â€¢ Fetches packet data     - DMA from mbuf buffers           â”‚ â”ƒ
â”ƒ  â”‚  â€¢ Transmits to wire       - Physical layer transmission     â”‚ â”ƒ
â”ƒ  â”‚  â€¢ Writes completions      - Update completion queue         â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                     â”ƒ
â”ƒ  ğŸ’¾ Hardware Queues:                                               â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”ƒ
â”ƒ  â”‚  âš¡ TX Queue (on NIC)                                      â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Hardware FIFO                                           â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Processes WQEs in order                                 â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Multiple queues supported (multi-queue/RSS)             â”‚  â”ƒ
â”ƒ  â”‚  â€¢ Size: Hardware-dependent                                â”‚  â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”ƒ
â”ƒ                                 â†“                                  â”ƒ
â”ƒ                        ğŸŒ [ Wire / Network ]                       â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
```

---

## 3. Data Structure Ownership & Lifecycle

### Overview Table

| Layer | Data Structures | Purpose | Typical Size |
|-------|-----------------|---------|--------------|
| **Application<br>(Pktgen)** | **Application RX/TX Rings**<br>(optional) | Software rings storing mbuf ptrs<br>Buffer packets before TX/after RX | Configurable<br>(nb_rxd/nb_txd) |
| **DPDK Core<br>Libraries** | **mbuf Mempool**<br>(TX-L1/P0/S0) | Packet buffer allocation/free<br>Pre-allocated mbufs<br>Shared across cores<br>Per-core cache | 32,768 mbufs<br>(configurable) |
| | **struct rte_mbuf** | Packet metadata & data buffer<br>Reference counting, offloads | 2176 bytes/mbuf |
| | **struct rte_eth_dev** | Function pointers to PMD<br>Port/Queue configuration<br>**No packet storage!** | Metadata only |
| **PMD<br>(MLX5)** | **WQE Ring Buffer** | Hardware descriptors<br>DMA-mapped memory<br>NIC reads directly | wqe_s<br>(e.g., 1024) |
| | **SW TX Queue**<br>(mlx5_txq_data) | Tracks mbuf pointers (elts[])<br>Queue indices (wqe_ci, wqe_pi)<br>Queue depth calculation | Same as WQE ring |
| | **Completion Queue** | Hardware completion notifications<br>Polled by driver | Configurable |
| **Hardware<br>(NIC)** | **On-chip TX FIFO** | Internal buffering<br>Not accessible by software | HW-dependent |

### Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Structure Lifecycle                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  [1] ALLOCATION (Initialization Phase)
      Application calls rte_mempool_create()
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ DPDK Core Libraries (Mempool)          â”‚
      â”‚  mbuf Mempool created (TX-L1/P0/S0)    â”‚
      â”‚  â€¢ Pre-allocates 32,768 mbufs          â”‚
      â”‚  â€¢ Sets up per-core caches             â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      Pktgen: pktgen_packet_ctor() fills packet templates

  [2] FAST PATH - GET MBUF
      Application calls rte_mempool_get_bulk(mp, mbufs[], count)
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ DPDK Core Libraries (Mempool)          â”‚
      â”‚  Returns pre-filled mbufs from pool    â”‚
      â”‚  (uses per-core cache for performance) â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      mbuf* array returned to application

  [3] SUBMISSION TO TX QUEUE
      Application calls rte_eth_tx_burst(port, queue, mbufs[], count)
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ DPDK Core Libraries (Ethdev)           â”‚
      â”‚  p->tx_pkt_burst() dispatch            â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      PMD: mlx5_tx_burst()
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ For each mbuf:                â”‚
      â”‚  1. Write WQE descriptor      â”‚ â† WQE Ring Buffer (PMD Layer)
      â”‚  2. Store mbuf pointer        â”‚ â† SW TX Queue (elts[])
      â”‚  3. Increment wqe_pi          â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      Ring doorbell (notify NIC)

  [4] HARDWARE PROCESSING
      NIC DMA reads WQEs and packet data
              â†“
      Transmit to wire
              â†“
      Write completion to CQ

  [5] COMPLETION & FREE
      PMD: mlx5_tx_handle_completion()
              â†“
      Poll Completion Queue
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ For each completion:          â”‚
      â”‚  1. Read elts[wqe_ci]         â”‚ â† Get mbuf pointer (PMD Layer)
      â”‚  2. Call rte_mempool_put_bulk â”‚ â”€â”
      â”‚  3. Increment wqe_ci          â”‚  â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
              â”‚                           â”‚
              â”‚                           â†“
              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚ DPDK Core Libraries (Mempool)      â”‚
              â”‚              â”‚  Returns mbufs to pool             â”‚
              â”‚              â”‚  (ready for next get_bulk call)    â”‚
              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      Loop continues (mbuf reuse pattern)
```

---

## 4. TX Path Flow with Data Structures

### Complete Step-by-Step Flow

#### STEP 1: Packet Initialization (One-time setup)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Layer (Pktgen)         â”‚
â”‚                                     â”‚
â”‚  rte_mempool_create()              â”‚ â”€â”€â†’ Create mbuf mempool
â”‚            â†“                        â”‚     (via DPDK Core Libraries)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DPDK Core Libraries (Mempool)      â”‚
â”‚                                     â”‚
â”‚  â€¢ Allocate 32,768 mbufs            â”‚
â”‚  â€¢ Setup per-core caches            â”‚
â”‚  â€¢ Return mempool handle            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Layer (Pktgen)         â”‚
â”‚                                     â”‚
â”‚  pktgen_packet_ctor()              â”‚ â”€â”€â†’ Fill packet templates
â”‚  â€¢ Pre-fill headers                 â”‚     (headers, patterns)
â”‚  â€¢ Setup packet patterns            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Code Location**: `pktgen.c:750+` (pktgen_packet_ctor)

**Key Point**: Mempool is **shared across cores** - potential contention point!

---

#### STEP 1.5: Fast Path - Get Pre-filled mbufs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Layer (Pktgen)         â”‚
â”‚                                     â”‚
â”‚  rte_mempool_get_bulk(mp,          â”‚ â”€â”€â†’ Request batch of mbufs
â”‚      mbufs[], count)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DPDK Core Libraries (Mempool)      â”‚
â”‚                                     â”‚
â”‚  â€¢ Check per-core cache first       â”‚
â”‚  â€¢ Return pre-filled mbufs          â”‚
â”‚  â€¢ Zero-copy (reuse pattern)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    mbufs[] ready for transmission
```

**Code Location**: `pktgen.c:1297+` (pktgen_send_pkts)

**Key API**: `rte_mempool_get_bulk()` NOT `rte_pktmbuf_alloc()`!

---

#### STEP 2: Submit to TX Queue

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Layer (Pktgen)         â”‚
â”‚                                     â”‚
â”‚  tx_send_packets(mbufs[], count)   â”‚ â”€â”€â†’ Batch mbufs into array
â”‚            â†“                        â”‚
â”‚  rte_eth_tx_burst(port, queue,     â”‚ â”€â”€â†’ Call DPDK Core API
â”‚                   mbufs[], count)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DPDK Core Libraries (Ethdev)       â”‚
â”‚                                     â”‚
â”‚  p->tx_pkt_burst(...)              â”‚ â”€â”€â†’ Dispatch to PMD via
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     function pointer
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PMD Layer (MLX5)                   â”‚
â”‚                                     â”‚
â”‚  mlx5_tx_burst(mbufs[], count)     â”‚
â”‚            â†“                        â”‚
â”‚  For each mbuf:                     â”‚
â”‚    1. Build WQE descriptor         â”‚ â”€â”€â†’ Write to WQE ring at wqe_pi
â”‚    2. Store mbuf pointer           â”‚ â”€â”€â†’ Save to elts[wqe_pi]
â”‚    3. Increment wqe_pi             â”‚ â”€â”€â†’ Advance producer index
â”‚            â†“                        â”‚
â”‚  Ring doorbell (MMIO write)        â”‚ â”€â”€â†’ Notify NIC of new packets
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        [ NIC ]
```

**Code Locations**:
- Application: `pktgen.c:463` (`tx_send_packets()`)
- DPDK Core Libraries: `dpdk/lib/ethdev/rte_ethdev.h` (inline function)
- PMD: `dpdk/drivers/net/mlx5/mlx5_tx.h` (`mlx5_tx_burst()`)

---

#### STEP 3: Hardware Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hardware (NIC)                     â”‚
â”‚                                     â”‚
â”‚  DMA reads WQEs                    â”‚ â”€â”€â†’ From WQE ring buffer
â”‚            â†“                        â”‚     (host memory)
â”‚  DMA reads packet data             â”‚ â”€â”€â†’ From mbuf data buffers
â”‚            â†“                        â”‚
â”‚  Transmit packets to wire          â”‚
â”‚            â†“                        â”‚
â”‚  Write completion entries          â”‚ â”€â”€â†’ To Completion Queue
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        [ Wire ]
```

**Key Point**: All DMA operations - no CPU involvement!

---

#### STEP 4: Completion Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PMD Layer (MLX5)                   â”‚
â”‚                                     â”‚
â”‚  mlx5_tx_handle_completion()       â”‚
â”‚            â†“                        â”‚
â”‚  Poll completion queue             â”‚ â”€â”€â†’ Read CQ entries (polling!)
â”‚            â†“                        â”‚
â”‚  mlx5_tx_free_mbuf()               â”‚
â”‚            â†“                        â”‚
â”‚  For each completed packet:         â”‚
â”‚    1. Read elts[wqe_ci]            â”‚ â”€â”€â†’ Get mbuf pointer
â”‚    2. rte_mempool_put_bulk()       â”‚ â”€â”
â”‚    3. Increment wqe_ci             â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
            â”‚                            â”‚
            â”‚                            â†“
            â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         â”‚  DPDK Core Libraries (Mempool)      â”‚
            â”‚         â”‚                                     â”‚
            â”‚         â”‚  â€¢ Return mbufs to pool             â”‚
            â”‚         â”‚  â€¢ Update per-core cache            â”‚
            â”‚         â”‚  â€¢ Ready for next get_bulk()        â”‚
            â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    mbuf reuse pattern continues
```

**Code Locations**:
- PMD: `dpdk/drivers/net/mlx5/mlx5_tx.h:542-567` (mlx5_tx_free_mbuf)
- DPDK Core Libraries: `dpdk/lib/mempool/rte_mempool.h` (rte_mempool_put_bulk)

**Key Point**: Polling-based (not interrupt-driven) for low latency!

---

## 5. Key Indices & Queue Depth Calculation

### WQE Ring Buffer Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WQE Ring Buffer (Size = 1024)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Consumer Index (wqe_ci)              Producer Index (wqe_pi)
            â†“                                    â†“
  â”â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”³â”â”â”â”â”“
  â”ƒFreeâ”ƒFreeâ”ƒUsedâ”ƒUsedâ”ƒUsedâ”ƒUsedâ”ƒFreeâ”ƒFreeâ”ƒFreeâ”ƒFreeâ”ƒFreeâ”ƒFreeâ”ƒ
  â”—â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”»â”â”â”â”â”›
  â”‚  0    1    2    3    4    5    6    7    8    9   10   11 ...â”‚
            â†‘                    â†‘
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               Queue Depth
            (In-flight packets)
```

### Formula & Calculation

```
Queue Depth = (wqe_pi - wqe_ci) mod wqe_s
```

**Example from Logs**:
```
wqe_ci = 648    (Consumer Index - packets completed by NIC)
wqe_pi = 351    (Producer Index - packets submitted by app)
wqe_s  = 1024   (Ring size - wraps around)

Calculation (with wraparound):
  wqe_used = (351 + 1024 - 648) mod 1024 = 727 mod 1024 = 297
```

**Interpretation**:
- âœ… **297 packets in flight** (waiting for completion)
- âœ… **29% queue utilization** (297 / 1024)
- âœ… **727 free slots available**

### Queue States

| Queue Depth | Utilization | Interpretation | Action Needed |
|-------------|-------------|----------------|---------------|
| < 10% | Very Low | NIC processing faster than app submission | Can increase TX rate |
| 20-50% | **Healthy** | Balanced state | âœ… Optimal |
| 50-80% | High | Queue filling up | Monitor for drops |
| > 80% | Critical | Risk of overflow | Reduce TX rate or increase queue size |

---

## 6. Our Tracking Points

### Tracking Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Tracking Points in Multi-Layer Stack                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  ğŸ“ [APPLICATION LAYER - pktgen.c:533-565]                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”‚
â”‚  âœ… Producer Count Tracking                                       â”‚
â”‚     â€¢ What: Packets submitted by application                      â”‚
â”‚     â€¢ When: Before rte_eth_tx_burst() call                       â”‚
â”‚     â€¢ Why: Counted once per batch (not per retry)                â”‚
â”‚     â€¢ Variable: ak_txq_stats[lcore_id].producer_count            â”‚
â”‚                                                                    â”‚
â”‚  âœ… Burst Interval Tracking                                       â”‚
â”‚     â€¢ What: Cycles between consecutive bursts                     â”‚
â”‚     â€¢ When: At start of each tx_send_packets() call              â”‚
â”‚     â€¢ Why: Measure actual rate limiting effectiveness            â”‚
â”‚     â€¢ Includes: Rate limiting delay + processing overhead         â”‚
â”‚     â€¢ Variable: ak_txq_stats[lcore_id].total_burst_interval      â”‚
â”‚                                                                    â”‚
â”‚  âœ… Burst Processing Time Tracking                                â”‚
â”‚     â€¢ What: Cycles to process one burst (incl. retry loop)       â”‚
â”‚     â€¢ When: tx_send_packets() entry â†’ exit                       â”‚
â”‚     â€¢ Why: Identify bottlenecks in TX path                       â”‚
â”‚     â€¢ Variable: ak_txq_stats[lcore_id].total_burst_processing    â”‚
â”‚                                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  ğŸ“ [PMD LAYER - mlx5_tx.h:679-688]                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  âœ… Consumer Count Tracking                                       â”‚
â”‚     â€¢ What: Packets completed by NIC                              â”‚
â”‚     â€¢ When: mlx5_tx_free_elts() (completion processing)          â”‚
â”‚     â€¢ Why: Measure actual NIC throughput                         â”‚
â”‚     â€¢ Variable: ak_txq_stats[lcore_id].consumer_count            â”‚
â”‚                                                                    â”‚
â”‚  ğŸ“ [PMD LAYER - mlx5_tx.h:3691-3715]                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚  âœ… Queue Depth Tracking                                          â”‚
â”‚     â€¢ What: WQE queue utilization (wqe_ci - wqe_pi)              â”‚
â”‚     â€¢ When: Every 10,000th completion (sampled for efficiency)   â”‚
â”‚     â€¢ Why: Monitor queue saturation                              â”‚
â”‚     â€¢ Variable: ak_txq_stats[lcore_id].total_depth               â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Metrics Collected

| Metric | Formula | Unit | Interpretation |
|--------|---------|------|----------------|
| **Producer Rate** | producer_count / duration | Mpps | App submission throughput |
| **Consumer Rate** | consumer_count / duration | Mpps | Actual NIC throughput |
| **P/C Ratio** | producer / consumer | ratio | 1.0 = balanced<br>> 1.0 = drops |
| **Avg Queue Depth** | total_depth / sample_count | packets | Queue utilization |
| **Avg Burst Interval** | total_burst_interval / burst_count | cycles | Actual burst spacing |
| **Avg Burst Processing** | total_burst_processing / burst_count | cycles | TX overhead |

---

## 7. Configuration Bug Fixed

### The Bug

**File**: `Pktgen-DPDK/app/pktgen-port-cfg.c:493`

#### âŒ BEFORE (Buggy Code)

```c
ret = rte_eth_tx_queue_setup(pid, q, pktgen.nb_rxd, pinfo->sid, &txq_conf);
                                     ^^^^^^^^^^^^^^
                                     Wrong! Using RX descriptor count
```

**Impact**:
- âŒ TX queue size = RX queue size (both 1024)
- âŒ Changing `DEFAULT_TX_DESC` had no effect
- âŒ `wqe_s` remained 1024 regardless of configuration
- âŒ Cannot independently tune TX/RX queue sizes

---

#### âœ… AFTER (Fixed Code)

```c
ret = rte_eth_tx_queue_setup(pid, q, pktgen.nb_txd, pinfo->sid, &txq_conf);
                                     ^^^^^^^^^^^^^^
                                     Correct! Using TX descriptor count
```

**Benefits**:
- âœ… TX queue size = `DEFAULT_TX_DESC` (configurable)
- âœ… Can adjust TX descriptor ring independently
- âœ… `wqe_s` reflects configured value
- âœ… Proper control over TX queue depth

---

### Configuration Flow

```
Application Layer:
  pktgen-constants.h:
    DEFAULT_TX_DESC = 2048   â† Can now configure this!
            â†“
  pktgen-main.c:462:
    pktgen.nb_txd = DEFAULT_TX_DESC
            â†“
  pktgen-port-cfg.c:493:
    rte_eth_tx_queue_setup(..., pktgen.nb_txd, ...)  â† Fixed!
            â†“
PMD Layer:
  MLX5 driver receives nb_txd and sets:
    txq->wqe_s = nb_txd
            â†“
Hardware:
  WQE ring allocated with wqe_s descriptors
```

---

## 8. Summary Table

### Layer-by-Layer Comparison

| Aspect | Application Layer | DPDK Core Libraries | PMD Layer | Hardware |
|--------|------------------|---------------------|-----------|----------|
| **ğŸ“ Code Location** | `Pktgen-DPDK/app/pktgen.c` | `dpdk/lib/mempool/`<br>`dpdk/lib/mbuf/`<br>`dpdk/lib/ethdev/` | `dpdk/drivers/net/mlx5/mlx5_tx.h` | NIC Firmware |
| **ğŸ”§ Main Functions** | `tx_send_packets()`<br>`pktgen_packet_ctor()` | Mempool:<br>â€¢ `rte_mempool_get_bulk()`<br>â€¢ `rte_mempool_put_bulk()`<br>Ethdev:<br>â€¢ `rte_eth_tx_burst()` | `mlx5_tx_burst()`<br>`mlx5_tx_handle_completion()`<br>`mlx5_tx_free_mbuf()` | DMA Engine |
| **ğŸ’¾ Data Structures** | â€¢ App RX/TX Rings<br>(optional) | Mempool:<br>â€¢ mbuf Mempool<br>â€¢ struct rte_mbuf<br>Ethdev:<br>â€¢ rte_eth_dev<br>(metadata only) | â€¢ WQE Ring<br>â€¢ SW TX Queue<br>â€¢ Completion Queue | On-chip FIFO |
| **âš™ï¸ Queue Size Config** | `nb_rxd/nb_txd`<br>âš ï¸ TX was buggy!<br>(used nb_rxd) | Mempool:<br>32,768 mbufs<br>Ethdev:<br>Pass-through | `wqe_s`<br>(based on nb_txd) | Fixed HW size |
| **ğŸ“Š Tracking Added** | â€¢ Producer count<br>â€¢ Burst interval<br>â€¢ Processing time | None | â€¢ Consumer count<br>â€¢ Queue depth | None |
| **ğŸ“ Typical Size** | 1024 descriptors<br>(nb_rxd/nb_txd) | 32K mbufs<br>(mempool) | 1024 descriptors<br>(wqe_s) | HW-dependent |
| **ğŸ¯ Responsibility** | Packet generation<br>Rate limiting<br>Retry logic | Mempool:<br>Memory pool mgmt<br>Per-core caching<br>Ethdev:<br>API abstraction<br>PMD dispatch | Hardware interface<br>Descriptor mgmt<br>Completion handling<br>mbuf lifecycle | DMA & TX |
| **ğŸ”„ APIs Used** | Calls:<br>â€¢ `rte_mempool_get_bulk()`<br>â€¢ `rte_eth_tx_burst()` | Provides:<br>â€¢ Mempool APIs<br>â€¢ Ethdev APIs<br>Used by:<br>â€¢ Application<br>â€¢ PMD | Calls:<br>â€¢ `rte_mempool_put_bulk()`<br>(in completion path) | Hardware ops<br>(DMA, TX) |

---

## Key Takeaways

### 1ï¸âƒ£ **Layered Architecture**
- Four distinct layers: Application â†’ DPDK Core Libraries â†’ PMD â†’ Hardware
- **DPDK Core Libraries** is an independent infrastructure layer containing:
  - Mempool Library (`dpdk/lib/mempool/`)
  - Mbuf Library (`dpdk/lib/mbuf/`)
  - Ethdev Library (`dpdk/lib/ethdev/`)
- Clean separation with well-defined APIs
- Function pointers enable driver abstraction (Ethdev â†’ PMD dispatch)

### 2ï¸âƒ£ **Mempool is NOT Part of Application or Ethdev**
- âœ… **Mempool is a separate DPDK Core Library**
- Located at `dpdk/lib/mempool/` (peer to `ethdev/` and `mbuf/`)
- Used by **both Application AND PMD layers**:
  - Application: `rte_mempool_get_bulk()` to get mbufs
  - PMD: `rte_mempool_put_bulk()` to return mbufs after completion
- Shared resource with per-core caching for performance

### 3ï¸âƒ£ **Multiple Queue Concepts and Physical Locations**

**âš ï¸ Terminology Clarification:**
- **SQ (Send Queue)** = **WQE Ring** = descriptor ring buffer (DMA-mapped memory)
- **TX Control Structure** = `struct mlx5_txq_data` = manages WQE Ring (NOT a queue!)
  - Contains: wqe_ci/wqe_pi (WQE Ring indices), wqes (â†’ WQE Ring), elts[] (mbuf pointers)
  - elts[] is **parallel** to WQE Ring: elts[i] stores mbuf pointer for WQE[i]
- **Why confusing naming?** "wqe_pi/wqe_ci" are indices **for the WQE Ring**, not for mlx5_txq_data itself

**âš ï¸ WQE Structure and Why elts[] is Needed:**
- **WQE = Hardware Descriptor = Work Instruction for NIC**
  - **NOT** "describing the hardware"
  - **YES** "describing how hardware should process data"
  - Tells NIC: "Read from this address, send this many bytes"
- **Each WQE contains**:
  - `pbuf`: DMA physical address (where to read, NOT mbuf pointer!)
  - `bcount`: Byte count to transmit (how many bytes)
  - `lkey`: Memory protection key
- **WQE does NOT contain mbuf pointer** because:
  - NIC hardware only understands DMA addresses (physical memory)
  - NIC cannot use virtual pointers (like `mbuf*`)
  - WQE is instruction, not the data itself
- **elts[] array tracks mbuf pointers in parallel**:
  - When WQE[i] is in-flight â†’ elts[i] stores corresponding mbuf*
  - On completion â†’ driver retrieves elts[i] to return mbuf to mempool
  - This is why elts[] is essential: it's the only place tracking which mbuf belongs to which WQE

**ğŸ“ Size Determination (both from same DEFAULT_TX_DESC parameter):**
- **Application**: Sets `DEFAULT_TX_DESC` (e.g., 1024) in config
- **PMD allocation** (`mlx5_txq.c:1135, 1168, 708`):
  - `elts[]` size = `desc` (exact value)
  - WQE Ring size = `1 << log2(desc)` (rounded to power of 2)
- **Key insight**: If `desc` is not power of 2, it's rounded up
  - Example: `desc=1000` â†’ both become 1024 (2^10)
  - Example: `desc=2048` â†’ both stay 2048 (2^11)
- **Result**: Both arrays always same size, guaranteeing 1:1 parallel mapping

**Physical Locations:**
- **Application**: Temporary working buffers (pointer arrays, ~32 entries)
  - Location: Host memory (application space)
- **DPDK Core Libraries**: mbuf mempool (packet buffer pool)
  - Location: Host memory (DMA-mapped)
- **PMD** (all in host memory!):
  - **WQE Ring/SQ**: Descriptor ring buffer
    - Location: **HOST MEMORY** (DMA-mapped, NOT on NIC chip!)
    - Evidence: `drivers/common/mlx5/mlx5_common_devx.c:118-127`
    - Allocated by PMD using `mlx5_malloc_numa_tolerant()`
    - Registered for DMA access with `mlx5_os_umem_reg()`
    - NIC reads descriptors from here via DMA
  - **Completion Queue (CQ)**: Completion status buffer
    - Location: Host memory (DMA-mapped)
    - NIC writes completion entries here via DMA
  - **TX Control Structure (mlx5_txq_data)**: Metadata/management
    - Location: Host memory (regular)
    - Driver uses this to manage WQE Ring (not accessed by NIC)
    - Contains parallel elts[] array tracking mbuf pointers
- **Hardware**: On-chip FIFO (internal NIC buffer)
  - Location: NIC chip (not accessible by software)
- **Key Insight**: Only the on-chip FIFO is actually on NIC hardware
  - WQE Ring, CQ, elts[] are all in **host RAM**
  - NIC accesses WQE Ring/CQ via DMA, not elts[]

### 4ï¸âƒ£ **Pktgen's Zero-Copy mbuf Reuse Pattern**
- **NOT using** `rte_pktmbuf_alloc()` / `rte_pktmbuf_free()` in fast path
- **Initialization**: Create packet templates once with `pktgen_packet_ctor()`
- **Fast path**: Use `rte_mempool_get_bulk()` to retrieve pre-filled mbufs
- **Completion**: PMD calls `rte_mempool_put_bulk()` to return mbufs
- Zero-copy optimization - no per-packet allocation overhead

### 5ï¸âƒ£ **Performance Tracking**
- Producer/Consumer tracking at different layers reveals bottlenecks
- Queue depth monitoring prevents overflow
- Burst timing measurements identify latency sources

### 6ï¸âƒ£ **Configuration Bug Fixed**
- TX/RX queue sizes must be independently configurable
- Bug: `pktgen-port-cfg.c:493` used `nb_rxd` instead of `nb_txd`
- Fix enables proper tuning of TX descriptor ring sizes
- Hardware queue size (`wqe_s`) now correctly derives from `nb_txd`

### 7ï¸âƒ£ **Complete Data Flow**
```
[Initialization]
rte_mempool_create() â†’ pktgen_packet_ctor() (fill templates)
     â†“
[Fast Path TX]
rte_mempool_get_bulk() â†’ rte_eth_tx_burst() â†’ mlx5_tx_burst() â†’
WQE write â†’ DMA read â†’ wire TX
     â†“
[Completion]
Poll CQ â†’ mlx5_tx_free_mbuf() â†’ rte_mempool_put_bulk() â†’ mbuf reuse
```

Each step involves different data structures and layers!

---

## References

- **DPDK Documentation**: https://doc.dpdk.org/guides/prog_guide/
- **MLX5 PMD Guide**: https://doc.dpdk.org/guides/nics/mlx5.html
- **Pktgen Documentation**: https://pktgen-dpdk.readthedocs.io/

---

**Last Updated**: 2025-01-05
**Project**: DPDK Performance Benchmarking & Optimization
**Repository**: `/homes/inho/Autokernel/dpdk-bench/`
